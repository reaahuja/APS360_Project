{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n",
    "        super(BasicConv, self).__init__()\n",
    "        self.out_channels = out_planes\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
    "        self.bn = nn.BatchNorm2d(out_planes,eps=1e-5, momentum=0.01, affine=True) if bn else None\n",
    "        self.relu = nn.ReLU() if relu else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        if self.relu is not None:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class ChannelGate(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max']):\n",
    "        super(ChannelGate, self).__init__()\n",
    "        self.gate_channels = gate_channels\n",
    "        self.mlp = nn.Sequential(\n",
    "            Flatten(),\n",
    "            nn.Linear(gate_channels, gate_channels // reduction_ratio),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(gate_channels // reduction_ratio, gate_channels)\n",
    "            )\n",
    "        self.pool_types = pool_types\n",
    "    def forward(self, x):\n",
    "        channel_att_sum = None\n",
    "        for pool_type in self.pool_types:\n",
    "            if pool_type=='avg':\n",
    "                avg_pool = F.avg_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( avg_pool )\n",
    "            elif pool_type=='max':\n",
    "                max_pool = F.max_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( max_pool )\n",
    "            elif pool_type=='lp':\n",
    "                lp_pool = F.lp_pool2d( x, 2, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( lp_pool )\n",
    "            elif pool_type=='lse':\n",
    "                # LSE pool only\n",
    "                lse_pool = logsumexp_2d(x)\n",
    "                channel_att_raw = self.mlp( lse_pool )\n",
    "\n",
    "            if channel_att_sum is None:\n",
    "                channel_att_sum = channel_att_raw\n",
    "            else:\n",
    "                channel_att_sum = channel_att_sum + channel_att_raw\n",
    "\n",
    "        scale = F.sigmoid( channel_att_sum ).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
    "        return x * scale\n",
    "\n",
    "def logsumexp_2d(tensor):\n",
    "    tensor_flatten = tensor.view(tensor.size(0), tensor.size(1), -1)\n",
    "    s, _ = torch.max(tensor_flatten, dim=2, keepdim=True)\n",
    "    outputs = s + (tensor_flatten - s).exp().sum(dim=2, keepdim=True).log()\n",
    "    return outputs\n",
    "\n",
    "class ChannelPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.cat( (torch.max(x,1)[0].unsqueeze(1), torch.mean(x,1).unsqueeze(1)), dim=1 )\n",
    "\n",
    "class SpatialGate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpatialGate, self).__init__()\n",
    "        kernel_size = 7\n",
    "        self.compress = ChannelPool()\n",
    "        self.spatial = BasicConv(2, 1, kernel_size, stride=1, padding=(kernel_size-1) // 2, relu=False)\n",
    "    def forward(self, x):\n",
    "        x_compress = self.compress(x)\n",
    "        x_out = self.spatial(x_compress)\n",
    "        scale = F.sigmoid(x_out) # broadcasting\n",
    "        return x * scale\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max'], no_spatial=False):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.ChannelGate = ChannelGate(gate_channels, reduction_ratio, pool_types)\n",
    "        self.no_spatial=no_spatial\n",
    "        if not no_spatial:\n",
    "            self.SpatialGate = SpatialGate()\n",
    "    def forward(self, x):\n",
    "        x_out = self.ChannelGate(x)\n",
    "        if not self.no_spatial:\n",
    "            x_out = self.SpatialGate(x_out)\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.name = \"cnn\"\n",
    "        # Input shape [128, 512, 7, 7] == [batch size, channels, feature map width, fm height]\n",
    "        self.conv1 = nn.Conv2d(512, 128, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.cbam1 = CBAM(128)\n",
    "        self.conv2 = nn.Conv2d(128, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.cbam2 = CBAM(64)\n",
    "        self.conv3 = nn.Conv2d(64, 32, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.cbam3 = CBAM(32)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(32 * 7 * 7, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.cbam1(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.cbam2(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.cbam3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "\n",
    "\n",
    "train_features, val_features, test_features = [], [], []\n",
    "\n",
    "# Remove the final fully connected layer\n",
    "model = nn.Sequential(*list(model.children())[:-2])\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "def get_features(loader, save):\n",
    "    for imgs, labels in loader:\n",
    "        with torch.no_grad():\n",
    "            features = model(imgs)  # Shape: [batch_size, 512, 7, 7]\n",
    "        save.append([features, labels])\n",
    "\n",
    "# Example usage with train_loader, val_loader, test_loader\n",
    "get_features(train_loader, train_features)\n",
    "get_features(val_loader, val_features)\n",
    "get_features(test_loader, test_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature, label = self.features[idx]\n",
    "        return feature.squeeze(), label\n",
    "\n",
    "train_dataset = FeatureDataset(train_features)\n",
    "val_dataset = FeatureDataset(val_features)\n",
    "test_dataset = FeatureDataset(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "import torch\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib as plt\n",
    "import torch.nn.functional as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, data, batch_size):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for imgs, labels in torch.utils.data.DataLoader(data, batch_size=batch_size):\n",
    "        if use_cuda and torch.cuda.is_available():\n",
    "            imgs = imgs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        output = model(imgs)\n",
    "\n",
    "        #select index with maximum prediction score\n",
    "        pred = output.max(1,keepdim = True)[1]\n",
    "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "        total += imgs.shape[0]\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, val_data=None, trial_num=0, batch_size=1, lr=0.01, num_epochs=10):\n",
    "    torch.manual_seed(1000)\n",
    "\n",
    "    if use_cuda and torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr, momentum=0.9)\n",
    "\n",
    "    iters, train_loss, val_loss, train_acc, val_acc = [], [], [], [], []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # training\n",
    "    n = 0 # the number of iterations\n",
    "    for epoch in range(num_epochs):\n",
    "        for imgs, labels in data_loader:\n",
    "            #print(imgs.shape)\n",
    "            #print(labels)\n",
    "            #print(\"Image shape before: \", imgs.shape)\n",
    "            #imgs = imgs.squeeze(0)\n",
    "            if use_cuda and torch.cuda.is_available():\n",
    "                imgs = imgs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            labels = labels.squeeze()\n",
    "\n",
    "            out = model(imgs)             # forward pass\n",
    "            loss = criterion(out, labels) # compute the total loss\n",
    "            loss.backward()               # backward pass (compute parameter updates)\n",
    "            optimizer.step()              # make the updates for each parameter\n",
    "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
    "\n",
    "        for imgs, labels in val_loader:\n",
    "            #print(imgs.shape)\n",
    "            #print(labels)\n",
    "            #print(\"Image shape before: \", imgs.shape)\n",
    "            #imgs = imgs.squeeze(0)\n",
    "            if use_cuda and torch.cuda.is_available():\n",
    "                imgs = imgs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            labels = labels.squeeze()\n",
    "\n",
    "            out = model(imgs)             # forward pass\n",
    "            v_loss = criterion(out, labels) # compute the total loss\n",
    "\n",
    "\n",
    "        # save the current training information\n",
    "        iters.append(n)\n",
    "        train_loss.append(float(loss)/batch_size)             # compute *average* loss\n",
    "        train_acc.append(get_accuracy(model, data, batch_size=batch_size)) # compute training accuracy\n",
    "\n",
    "\n",
    "        val_acc.append(get_accuracy(model, val_data, batch_size=batch_size))  # compute validation accuracy\n",
    "        val_loss.append(float(v_loss)/batch_size)\n",
    "        n += 1\n",
    "\n",
    "\n",
    "        if val_data != None:\n",
    "            print(f\"Epoch {epoch + 1}: Train acc: {train_acc[-1]} | Validation acc: {val_acc[-1]}\")\n",
    "        else:\n",
    "            print(f\"Epoch {epoch + 1}: Train acc: {train_acc[-1]}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Total time elapsed: {elapsed_time:.2f} s\")\n",
    "\n",
    "    # plot\n",
    "    plt.title(\"Training Curve\")\n",
    "    plt.plot(iters, train_loss, label=\"Train\")\n",
    "    plt.plot(iters, val_loss, label=\"Validation\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Training Curve\")\n",
    "    plt.plot(iters, train_acc, label=\"Train\")\n",
    "    plt.plot(iters, val_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Training Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
    "    if val_data != None:\n",
    "        print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf0312fc0196bf1a3e5726f9bcd9cfae20af3d56a9ad58001749fea87a7eb0e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
